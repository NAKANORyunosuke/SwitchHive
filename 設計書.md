# 転倒検知・画像保存モジュール 仕様書（Camera → Fall Detection → Image Save）

- バージョン: 0.9.0
- 更新日: 2025-09-10
- 対象: エッジ端末（CPUオンリーを想定）で、カメラ映像から軽量に転倒を検知し、画像（およびメタデータ）を保存するコンポーネント
- スコープ: **カメラ入力 → 転倒判定 → 画像保存**  
  ※ 通知（Azure/LINE等）や音声アラートは本仕様の範囲外。ただし拡張IFを付録に記載。

---

## 1. 目的
転倒イベントを低遅延・低負荷で検出し、証跡（画像・メタデータ）を確実に保存する。誤検知を抑えつつ、事後確認に十分なコンテキスト（事前数秒・事後数秒）を提供する。

---

## 2. 用語
- **フレーム**: カメラから取得した単一画像。
- **推論FPS**: 転倒判定に供するフレームレート。I/Oの実FPSとは異なり、間引き可能。
- **ポーズ推定**: 人体の主要骨格点（関節）を検出する処理（例: 17～33点）。
- **イベント**: 転倒判定ロジックが真となった時点を起点とする一連の保存処理単位。
- **前後バッファ**: イベント時点の前後に保存するフレーム群（例: 事前2秒・事後3秒）。

---

## 3. システム概要

```
[Camera] → [Capture] → [Preprocess] → [Pose Estimator] → [Fall Logic FSM] → [Event Queue] → [Image Saver]
│
└──→ [Metrics/Logs]
```

- **Capture**: カメラI/O（USB/RTSP/ファイル）・タイムスタンプ付与・リングバッファ維持
- **Preprocess**: リサイズ・正規化・レターボックス
- **Pose Estimator**: 軽量モデル（例: MoveNet/BlazePose/YOLO-Pose系のいずれか）で骨格点+信頼度を出力
- **Fall Logic FSM**: しきい値＋時系列ルール＋ヒステリシスで転倒判定（多人数時は簡易トラッキング）
- **Event Queue**: 非同期保存のためのキュー（落下イベント単位）
- **Image Saver**: 画像（注釈入り/生フレーム）＋メタデータ(JSON)をディスクに保存

---

## 4. 入力仕様（カメラ）

### 4.1 対応ソース
- `device_index`: 例 `0`（USBカメラ）
- `rtsp_url`: 例 `rtsp://user:pass@host:554/stream`
- `file_path`: 例 `sample.mp4`（検証用）

### 4.2 キャプチャ設定
- 解像度: 1280×720（推奨）。最小 640×480。
- I/O FPS: 30fps（推奨）。非固定でも可。
- 推論FPS: 10～15fps（既定=12）。I/Oから間引き可。
- タイムスタンプ: 協定世界時（UTC, ISO 8601, `Z`付き）を使用。NTPでの時刻同期必須。

---

## 5. 転倒判定ロジック

### 5.1 前提
- ポーズ推定から各骨格点 `(x, y, score)` を取得（少なくとも肩・腰・膝周りが有効）。
- 低信頼フレームの除外: 有効関節数が `min_conf_joints` 未満の場合は判定スキップ。
- 多人数: バウンディングボックスの近傍一致（IoUまたは重心距離）でフレーム間対応付け。

### 5.2 特徴量（1人トラックごと）
- **上体傾き角 θ**: 肩中心→腰中心ベクトルと鉛直のなす角（度）。直立=0°, 横向き=90°。
- **縦横比 r**: 人物の骨格点包絡矩形の `h / (w + ε)`。直立で大、横たわると小。
- **腰中心の降下量 Δy**: 直近 `T_drop` 秒の hip_y の増分（画面座標で下向きを正）。
- **静止度 S**: 直近 `T_still` 秒の速度（|Δy| 等）の平均が `v_still` 未満。

### 5.3 ルール（AND 条件, ヒステリシス付き）
- A: `θ > angle_deg_th` **または** `r < ratio_th` の状態が `T_pose` 秒以上継続  
- B: `Δy > hip_drop_px_th`（`T_drop` 秒内の急降下）  
- C: A∧B後、`T_still` 秒間 `S < v_still`（静止）  
- D: 人物高さ `h_person >= min_person_height_px`（スケール/遠景での誤検知抑制）  
- **転倒確定**: A ∧ B ∧ C ∧ D が真になった瞬間にイベント発火。  
- **クールダウン**: 発火後 `cooldown_sec` の間は同一人物の再発火を抑制。

### 5.4 代表しきい値（初期値）
- `angle_deg_th = 55°`
- `ratio_th = 0.60`
- `T_pose = 0.5 s`
- `hip_drop_px_th = 40 px`（720p基準。画角により再調整）
- `T_drop = 0.4 s`
- `T_still = 1.0 s`
- `v_still = 0.5 px/frame`
- `min_person_height_px = 120 px`
- `cooldown_sec = 5 s`

※ しきい値は設置環境（カメラ高・画角）に応じてキャリブレーション必須。

---

## 6. 出力仕様（保存）

### 6.1 ディレクトリ構成
- ルート: `base_dir`（例 `/var/lib/falls`）
- パス:  
  `/{base_dir}/{camera_id}/{YYYY}/{MM}/{DD}/{event_id}/`

### 6.2 ファイル命名
- `event_id`: `YYYYMMDDThhmmssZ_{camera_id}_fall_{seq}`（UTC, 連番付き）
- 静止画（注釈付き）: `annotated_{t_rel_ms}.jpg`  
  - `t_rel_ms`: イベント起点からの相対時刻（負=事前, 正=事後）
- 静止画（生フレーム, 任意）: `raw_{t_rel_ms}.jpg`
- メタデータ: `event.json`
- クリップ（任意）: `clip.mp4`

### 6.3 保存範囲と品質
- 前後バッファ: `pre_seconds=2`, `post_seconds=3`
- 画像形式: `jpg`（`jpeg_quality=90`）
- クリップ: `enabled=true`, `fps=15`, `max_seconds=6`, `codec=mp4v`

### 6.4 画像注釈（annotated）
- 人物バウンディング、骨格点・骨格線、しきい値判定の要約（θ, r, Δy, S）
- 画面左下に `camera_id`, `timestamp(UTC)`, `event_id`, `model_version`

### 6.5 メタデータ（`event.json`）
フィールド例（最低限）:
- `event_id` (string)
- `camera_id` (string)
- `timestamp_utc` (ISO 8601, `Z`)
- `model`:
  - `backend` (`tflite` | `onnx` | `opencv-dnn`)
  - `model_name` (string), `model_version` (string), `num_threads` (int)
- `decision`:
  - `angle_deg_th`, `ratio_th`, `hip_drop_px_th`, `T_pose`, `T_drop`, `T_still`, `v_still`, `min_person_height_px`, `cooldown_sec`
  - `features_at_trigger`: `theta_max`, `ratio_min`, `hip_drop`, `still_score`
- `track_id` (int) — 多人数時の内部ID
- `frames`:
  - `pre_ms` (int), `post_ms` (int), `inference_fps` (float)
  - `saved_files`: 配列（ファイル名・種別 `annotated|raw`・相対時刻ms）
- `privacy`:
  - `face_blur` (bool), `blur_kernel` (int), `redact_metadata` (bool)
- `system`:
  - `host` (string), `app_version` (string), `git_commit` (string, 任意)

---

## 7. 設定（コンフィグ）

**形式**: YAML or JSON（UTF-8）。起動時に読み込み、ホットリロードは任意。

例（YAML想定）:
    camera:
      source: "0"         # "0" | "rtsp://..." | "/path/to/file"
      width: 1280
      height: 720
      fps: 30
      inference_fps: 12
      camera_id: "cam01"

    model:
      backend: "tflite"   # "tflite" | "onnx" | "opencv-dnn"
      model_path: "./models/movenet_lightning.tflite"
      num_threads: 2

    detection:
      min_conf_joints: 8
      angle_deg_th: 55
      ratio_th: 0.6
      T_pose_sec: 0.5
      hip_drop_px_th: 40
      T_drop_sec: 0.4
      T_still_sec: 1.0
      v_still_px_per_frame: 0.5
      min_person_height_px: 120
      cooldown_sec: 5

    saver:
      base_dir: "/var/lib/falls"
      save_annotated: true
      save_raw: false
      pre_seconds: 2
      post_seconds: 3
      image_format: "jpg"
      jpeg_quality: 90
      video_clip:
        enabled: true
        fps: 15
        max_seconds: 6
        codec: "mp4v"

    privacy:
      face_blur: true
      blur_kernel: 31
      encrypt_at_rest: true
      retention_days: 30
      redact_metadata: true

    logging:
      level: "INFO"
      file: "/var/log/falldetector/app.log"
      export_prometheus: true

---

## 8. 例外・エラーハンドリング

### 8.1 カメラ関連
- ソース未接続/RTSP途切れ: リトライ（指数バックオフ最大 60s）。状態遷移をログ出力。
- フレームドロップ: 推論側でスキップ、I/O側は継続。

### 8.2 モデル関連
- モデルロード失敗/未対応OP: 起動エラーとして明示的に終了。`exit_code=101`。
- 推論タイムアウト（> 200ms/フレームが連続 N 回）: 警告ログ、推論FPSを自動低下。

### 8.3 ディスク関連
- 空き容量閾値（例 5%）未満: もっとも古いイベントを自動削除（`retention_days` に優先）。削除ログを監査に残す。
- 書き込み失敗: リトライ3回→失敗時にイベントを`FAILED_SAVE`として記録。

### 8.4 プライバシー
- 顔検出失敗時: 画像保存は続行するが、`event.json.privacy.face_blur_failed=true` を追記（運用方針により保存中止も可）。

---

## 9. ログとメトリクス

### 9.1 ログ（構造化）
- 重要レベル: `INFO`（イベント発生/保存完了）, `WARN`（一過性エラー）, `ERROR`（処置必要）
- 例:  
  `ts, level, camera_id, msg, event_id, track_id, fps_io, fps_infer, cpu_pct, mem_mb`

### 9.2 メトリクス
- `fps_io`, `fps_infer`, `inference_latency_ms_p50/p95`
- `events_total`, `false_positive_manual`（後検証入力を想定）
- `disk_free_pct`, `save_fail_count`

---

## 10. 性能要件（目標値）
- レイテンシ: 推論1フレーム ≤ 30–60ms（720p, CPU 4C8Tクラス）
- 推論FPS: 10–15fps を安定維持
- 誤報率: 1台あたり**1回/日以下**（運用チューニング後）
- 漏検率: 実地検証データで **< 10%** を目標（データ依存）

---

## 11. セキュリティ・プライバシー
- 保存先の**暗号化（encrypt_at_rest）**を推奨（LUKS/BitLocker等、またはアプリ層暗号）。
- 顔の**モザイク**（`face_blur=true`）既定有効。
- ファイルアクセス権: `umask 077`、アプリ専用ユーザ。
- メタデータの個人特定情報は記録しない（`redact_metadata=true`）。

---

## 12. テスト計画

### 12.1 単体テスト
- 入力なし/破損フレーム/極端照度での前処理
- ポーズ推定が低信頼のときのスキップ判定

### 12.2 結合テスト
- 疑似データ（座る/しゃがむ/横になる/転倒）の再生とイベント発火回数の検証
- 多人数・入退室の頻発でのトラッキング健全性

### 12.3 システムテスト（実機）
- 実カメラ・設置環境での1週間の連続稼働
- ディスク満杯近傍でのローテーション挙動

### 12.4 受入基準（例）
- 必要時に**注釈付き画像**が**前後バッファ含め**保存されていること
- メタデータの必須項目が欠落しないこと
- 誤報率・漏検率が運用合意値以内

---

## 13. 非機能要件
- 可用性: 自動再起動（watchdog/systemd）、障害時の状態復帰（未保存キューの再処理）
- 観測可能性: 構造化ログ＋Prometheusエクスポート（任意）
- 設定管理: バージョニング（`app_version`, `git_commit`）のイベント書き込み

---

## 14. 実装ガイド（参考・必須ではない）

### 14.1 スレッド/プロセス設計（推奨）
- `capture_thread`: フレーム取得＋リングバッファ（例: 5秒分）
- `infer_thread`: `inference_fps` に合わせて取り出し、ポーズ推定＋ロジック
- `saver_worker`: Event Queue を監視して保存処理

### 14.2 モデル選択（いずれか）
- `tflite`: MoveNet Lightning（低レイテンシ）
- `onnx`/`opencv-dnn`: YOLO系Pose（nano/軽量）
- モデルは入替可能とし `model.backend` / `model.model_path` で切替

---

## 15. 既知の限界と対策
- 毛布/布団など**横臥**と転倒の区別が難しい → 事前プロファイル（寝具のある部屋は `angle_deg_th` を上げる）
- 強い逆光/影 → 自動露光の固定、`min_person_height_px` を上げる
- 低身長/遠距離でのスケール問題 → 画角最適化、`hip_drop_px_th` を比率基準へ切替（画面高に対する%）

---

## 付録A. 設定スキーマ（抜粋, JSON Schema 風）

    detection:
      angle_deg_th: number (0–90)
      ratio_th: number (0–1)
      T_pose_sec: number (>0)
      hip_drop_px_th: integer (>0)
      T_drop_sec: number (>0)
      T_still_sec: number (>0)
      v_still_px_per_frame: number (>=0)
      min_person_height_px: integer (>0)
      cooldown_sec: number (>=0)

    saver:
      base_dir: string (abs path)
      save_annotated: boolean
      save_raw: boolean
      pre_seconds: number (>=0)
      post_seconds: number (>=0)
      image_format: enum ["jpg","png"]
      jpeg_quality: integer (1–100)
      video_clip:
        enabled: boolean
        fps: integer (>0)
        max_seconds: number (>0)
        codec: string

---

## 付録B. イベントJSON 例（整形）

    {
      "event_id": "20250910T120501Z_cam01_fall_0007",
      "camera_id": "cam01",
      "timestamp_utc": "2025-09-10T12:05:01Z",
      "model": {
        "backend": "tflite",
        "model_name": "movenet_lightning",
        "model_version": "1.0.0",
        "num_threads": 2
      },
      "decision": {
        "angle_deg_th": 55.0,
        "ratio_th": 0.6,
        "hip_drop_px_th": 40,
        "T_pose": 0.5,
        "T_drop": 0.4,
        "T_still": 1.0,
        "v_still": 0.5,
        "min_person_height_px": 120,
        "cooldown_sec": 5,
        "features_at_trigger": {
          "theta_max": 72.3,
          "ratio_min": 0.51,
          "hip_drop": 63.0,
          "still_score": 0.3
        }
      },
      "track_id": 3,
      "frames": {
        "pre_ms": 2000,
        "post_ms": 3000,
        "inference_fps": 12,
        "saved_files": [
          {"file":"annotated_-1800.jpg","kind":"annotated","t_rel_ms":-1800},
          {"file":"annotated_0.jpg","kind":"annotated","t_rel_ms":0},
          {"file":"annotated_1200.jpg","kind":"annotated","t_rel_ms":1200}
        ]
      },
      "privacy": {
        "face_blur": true,
        "blur_kernel": 31,
        "redact_metadata": true
      },
      "system": {
        "host": "edge-node-01",
        "app_version": "0.9.0",
        "git_commit": "abc1234"
      }
    }

---

## 付録C. 拡張IF（通知用 Webhook; スコープ外・将来拡張）
- エンドポイント（HTTP POST）: `/events/fall`
- 送信ボディ: `event.json` と同等、またはそのサマリ（`event_id`, `camera_id`, `timestamp_utc`, 代表画像の相対パス）
- 冪等性: `event_id` をキーに重複受理を抑制
- セキュリティ: `HMAC-SHA256` シグネチャヘッダ（共有鍵）

---

## 変更履歴
- 0.9.0: 初版（転倒判定ロジック・保存仕様・設定スキーマ・テスト計画を定義）
